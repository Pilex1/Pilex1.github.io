<!doctype html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Bootstrap CSS -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.0-beta1/dist/css/bootstrap.min.css" rel="stylesheet"
    integrity="sha384-0evHe/X+R7YkIZDRvuzKMRqM+OrBnVFBL6DOitfPri4tjfHxaWutUpFmBp4vmVor" crossorigin="anonymous">

  <link rel="stylesheet" href="/assets/css/styles.css">

  <link rel="icon" type="image/png" href="/assets/img/favicon.png">


  <script src="https://code.jquery.com/jquery-3.3.1.min.js" crossorigin="anonymous"></script>

  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js"
    integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM"
    crossorigin="anonymous"></script>


  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      },
      startup: {
        ready: () => {
          MathJax.startup.defaultReady();
          MathJax.startup.promise.then(() => {
            // console.log('MathJax initial typesetting complete');

            // a hack, but you need this for lines created using \rule to be rendered in the correct colour
            $("rect").removeAttr("fill");
          });
        }
      }

    };
  </script>
  <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
  </script>

  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjs/10.6.0/math.js"></script>

  
  

</head>

<body>
  <!-- special case to handle the index page -->



    
    

    
    

    
    

    
    
        <h1 class="text-center">Machine Learning</h1>
        <p class="text-center">And human learning too</p>
        
    




<nav class="justify-content-center">
    
        <a href="/index">
            Home
        </a>
    
        <a href="/computer-graphics/index">
            Computer Graphics
        </a>
    
        <a href="/visualizations/index">
            Mathematical Visualizations
        </a>
    
        <a href="/machine-learning/index">
            Machine Learning
        </a>
    
</nav>
  <div class="container">
    <div class="row my-2">
        <div class="col col-lg-6 mx-auto">
            
            
            
            
            
            
            
            
            
            
            
            
            <div class="card">
                <div class="card-body">
                    <h4 class="card-title">Quick links</h4>
                    
                    
                    
                    <a class="d-block" href="/machine-learning/jacobian">Jacobian matrix</a>
                    
                    
                    
                    
                    <a class="d-block" href="/machine-learning/chain-rule">Chain rule for vector-to-vector functions</a>
                    
                    
                    
                    
                    <a class="d-block" href="/machine-learning/linear-regression">Linear regression</a>
                    
                    
                    
                    
                    <a class="d-block" href="/machine-learning/neural-networks-1">Neural networks part 1</a>
                    
                    
                    
                    
                    <a class="fw-bold text-light">Neural networks part 2</a>

                    

                    
                    
                    
                </div>
            </div>
            
            
        </div>
    </div>
    <div class="row">
        <div class="col col-12">
            <h1>Neural networks part 2</h1>
        </div>
    </div>
</div>

  <script id="dsq-count-scr" src="//pilex-github.disqus.com/count.js" async></script>

  <div class="container">
    <div class="row">
      <div class="col col-12">
        <h2 id="bias-term">Bias term</h2>

<p>In our setup so far, at each layer $\ell$ the inputs $a^{[\ell-1]}$ are matrix-multiplied by a set of weights, to produce the $z$ values i.e.</p>

\[z_i^{[\ell]}={a^{[\ell-1]}}^T\cdot w_i\]

<p>Like we did in linear regression, we typically also add a bias term to this so that we have</p>

\[z_i^{[\ell]}={a^{[\ell-1]}}^T\cdot w_i+b_i^{[\ell]}\]

<p>Again, like we did in linear regression, an easy way to account for this is to add an extra component to all the inputs with a constant value of 1, and add an extra component to the weights. In our vectorized setup, this would correspond with adding an extra column of 1s at the far right of each $A^{[\ell-1]}$, and the weight matrices $W^{[\ell]}$ having an extra row at the bottom. The bias terms would then be updated by gradient descent in the same way the weight terms are updated.</p>

<p>Alternatively, we can explicitly write out the equations involving the bias term and compute the partial derivatives explicitly. In vectorized form, arrange the $b_i^{[\ell]}$ into a row vector</p>

\[b^{[\ell]}=\begin{bmatrix}
b_1^{[\ell]}&amp;
b_2^{[\ell]}&amp;
\cdots&amp;
b_{n^{[\ell]}}^{[\ell]}
\end{bmatrix}\]

<p>Then compute</p>

\[Z^{[\ell]}={A^{[\ell-1]}}^T\cdot W+b^{[\ell]}\]

<p>where the addition here is between a matrix and a row vector, and is interpreted to mean that the addition is broadcasted over all the rows of the matrix i.e. the addition looks like</p>

\[Z^{[\ell]}={A^{[\ell-1]}}^T\cdot W+\begin{bmatrix}
\rule[.5ex]{2.5ex}{0.5pt}b^{[\ell]}\rule[.5ex]{2.5ex}{0.5pt}\\
\vdots\\
\rule[.5ex]{2.5ex}{0.5pt}b^{[\ell]}\rule[.5ex]{2.5ex}{0.5pt}\\
\end{bmatrix}\]

<h3 id="matrix-calculus-broadcasted-addition">Matrix calculus: broadcasted addition</h3>

<p>We now need to work out what the derivative of broadcast addition looks like within our matrix calculus frameowrk. Following the notation from our framework, let</p>

\[G:X\mapsto C+X\]

<p>where $X\in\mathbb R^{1\times n}$ is a row vector, $C\in\mathbb R^{m\times n}$ is a constant matrix, and the addition is broadcasted. If $f$ is a matrix-to-scalar function taking $G$ as input, then</p>

\[\begin{align*}
\frac{df}{dX_{1,j}}&amp;=\sum_{k,\ell}\frac{df}{dG_{k,\ell}}\cdot\frac{dG_{k,\ell}}{dX_{1,j}}\tag{multivariable chain rule}\\
&amp;=\sum_{k,\ell}\frac{df}{dG_{k,\ell}}\cdot\frac{d}{dX_{1,j}}(C_{k,\ell}+X_{1,\ell})\\
&amp;=\sum_{k,\ell}\frac{df}{dG_{k,\ell}}\cdot 1_{\ell=j}\\
&amp;=\sum_{k}\frac{df}{dG_{k,j}}\\
\implies \frac{df}{dX}&amp;=\sum_{\text{rows}}\frac{df}{dG}.
\end{align*}\]

<p>Analogously, we can look at columnwise broadcasting. If</p>

\[G:X\mapsto C+X\]

<p>where $X\in\mathbb R^{m\times 1}$ is a <em>column</em> vector, $C\in\mathbb R^{m\times n}$, and the addition is broadcasted, then using similar reasoning,</p>

\[\frac{df}{dX}=\sum_{\text{columns}}\frac{df}{dG}.\]

<h3 id="tying-things-together">Tying things together</h3>

<p>We can now go back to what we were doing before. Recall we had</p>

\[Z^{[\ell]}={A^{[\ell-1]}}^T\cdot W+b^{[\ell]}\]

<p>where the addition is broadcasted between a matrix and row vector. Then our results above tell us that (with $G:b^{[\ell]}\mapsto {A^{[\ell-1]}}^T\cdot W+b^{[\ell]}=Z^{[\ell]}$ and $f:Z^{[\ell]}\mapsto\cdots$)</p>

\[\frac{df}{db^{[\ell]}}=\sum_{\text{rows}}\frac{df}{dZ^{[\ell]}}\]

<h2 id="regression-with-multiple-outputs">Regression with multiple outputs</h2>

<p>So far our neural network has been predicting a single real value. Sometimes we may want to have multiple outputs i.e. $y^{(i)}\in\mathbb R^n$. Previously, we minimized the mean squared error between the modelâ€™s predictions and the actual values, where the error was simply the difference between the predictions and true values $\hat y^{(i)}-y^{(i)}$. When the output is a vector, we can extend this to the $L_2$ norm between the predictions and true values</p>

\[f(W)=\frac 1m\sum_{i=1}^m\Vert \hat y^{(i)}-y^{(i)}\Vert_2^2\]

<p>To vectorize the setup, place the $y^{(i)}$ as rows of a matrix $Y$ as before:</p>

\[Y=\begin{bmatrix}
\rule[.5ex]{2.5ex}{0.5pt}{y^{(1)}}^T\rule[.5ex]{2.5ex}{0.5pt}\\
\vdots\\
\rule[.5ex]{2.5ex}{0.5pt}{y^{(m)}}^T\rule[.5ex]{2.5ex}{0.5pt}\\
\end{bmatrix}.\]

<p>The weight matrix in the last layer will need to have its shape suitably adjusted to produce predictions of the correct shape. Then the loss function in vectorized form becomes</p>

\[\frac 1m \Vert A^{[L]}-Y\Vert_F^2\]

<p>which is the same as what we had before. Recall, however, that when we had a scalar output, $A^{[L]}-Y$ was a column vector in disguise and taking the Frobenius norm was really the same as taking the $L_2$ norm. Now, $A^{[L]}-Y$ is a proper matrix and we take the Frobenius norm of this matrix.</p>

<h2 id="binary-classification">Binary classification</h2>

<p>We have looked at how to do regression: predicting a real value (or vector of real values). Sometimes we want to perform classification instead, where we classify an example into one out of a discrete number of classes. We start with the simplest of these: binary classification. Here there are two classes and we want to predict which class an example falls into.</p>

<p>The way this is typically done is to take our setup for a neural network for regression with a scalar output, and use a sigmoid function as activation for the last layer so that the output lies in the range $[0,1]$. Examples with a prediction closer to 0 fall into one class, and examples with a prediction closer to 1 fall into the other. You can think of this value as the probability that the example belongs to one of the classes.</p>

<p>Also, instead of using mean squared error as the loss, we typically use binary cross-entropy instead. For a single example, binary cross-entropy is defined as</p>

\[-y^{(i)}\log_2\hat y^{(i)}-(1-y^{(i)})\log_2(1-\hat y^{(i)})\]

<p>which is equivalent to</p>

\[\begin{cases}
-\log_2\hat y ^{(i)},&amp;y^{(i)}=1\\
-\log_2(1-\hat y^{(i)}),&amp;y^{(i)}=0
\end{cases}\]

<p>Using this form, we see that if the true value is 1 ($y^{(i)}=1$) then if the prediction is also 1, the loss is 0. However, as the predicted value approaches 0, the binary cross-entropy approaches positive infinity. Conversely, if the true value is 0 ($y^{(i)}=0$) then if the prediction is also 0, the loss is 0. As the predicted value approaches 1, the binary cross-entropy again approaches positive infinity.</p>

<p>We will use the first form from here, however, as this expresses binary cross-entropy as a differentiable function.</p>

<p>Taking into account all the training examples, we want to find weights so as to minimize the mean binary cross-entropy over all the training examples</p>

\[f(W)=\frac 1m\sum_{i=1}^m\left[-y^{(i)}\log_2\hat y^{(i)}-(1-y^{(i)})\log_2(1-\hat y^{(i)})\right]\]

<p>Since the $y^{(i)}$ and $\hat y^{(i)}$ are arranged as rows in the matrices $Y$ and $A^{[L]}$ respectively, we have</p>

\[\begin{align*}
f(W)&amp;=\frac 1m\sum_{i=1}^m\left(-Y_i\log_2 A^{[L]}_i-(1-Y_i)\log_2(1-A^{[L]}_i)\right)\\
&amp;=-\frac 1m\left(\left(\sum_{i=1}^mY_i\log_2 A^{[L]}_i\right)+\left(\sum_{i=1}^m(1-Y_i)\log_2(1-A^{[L]}_i)\right)\right)\\
&amp;=-\frac 1m\left(Y^T\cdot\log_2\circ A^{[L]}+(1-Y)^T\cdot\log_2\circ (1-A^{[L]})\right)
\end{align*}\]

<p>Taking the partial derivative with respect to $A^{L}$ using our matrix calculus framework gives</p>

\[\begin{align*}
\frac{df}{dA^{[L]}}&amp;=-\frac 1m\left(\frac{d}{dA^{[L]}}\left(Y^T\cdot \log_2\circ A^{[L]}\right)+\frac{d}{dA^{[L]}}\left((1-Y)^T\cdot \log_2\circ (1-A^{[L]})\right)\right)\\
&amp;=-\frac 1m\left(Y\cdot\frac{d}{dA^{[L]}}\left(\log_2\circ A^{[L]}\right)+(1-Y)\cdot\frac{d}{dA^{[L]}}\left(\log_2\circ(1-A^{[L]}\right)\right)\\
&amp;=-\frac 1m\left(Y\cdot\frac{1}{\ln 2}\oslash A^{[L]}+(1-Y)\cdot\frac{-1}{\ln 2}\oslash(1-A^{[L]})\right)\\
&amp;=\frac{1}{m\ln 2}\left((1-Y)\oslash(1-A^{[L]})-Y\oslash A^{[L]}\right)
\end{align*}\]

<p>Since we are using the sigmoid activation function for the last layer, we have</p>

\[A^{[L]}=\sigma\circ Z^{[L]}\]

<p>and we also have (exercise for the reader)</p>

\[\sigma'=\sigma\cdot (1-\sigma)\]

<p>We can then simplifiy $\frac{df}{dZ^{[L]}}$ as follows</p>

\[\begin{align*}
\frac{df}{dZ^{[L]}}&amp;=\frac{df}{dA^{[L]}}\odot (\sigma'\circ Z^{[L]})\\
&amp;=\frac{1}{m\ln 2}\left((1-Y)\oslash(1-A^{[L]})-Y\oslash A^{[L]}\right)\odot (\sigma\circ Z^{[L]})\odot ((1-\sigma)\circ Z^{[L]})\\
&amp;=\frac{1}{m\ln 2}\left((1-Y)\oslash(1-A^{[L]})-Y\oslash A^{[L]}\right)\odot A^{[L]}\odot (1-A^{[L]})\\
&amp;=\frac{1}{m\ln 2}\left((1-Y)\odot A^{[L]}-Y\odot (1-A^{[L]})\right)
\end{align*}\]

<h2 id="multi-class-classification">Multi-class classification</h2>

<p>If we want to perform classification over more than two classes, we need to modify our setup from binary classification a bit. Let $C$ denote the number of classes. Instead of having a scalar output, we now have a vector output in $\mathbb R^C$. The $j$th component of this vector represents the probability or confidence of the model that the particular example belongs to class $j$. To ensure that the individual components lie in the range $[0,1]$ and that they add up to 1, we use a softmax activation function for the last layer</p>

\[a^{[L]}_j=\frac{\exp(z^{[L]}_j)}{\sum_{i=1}^C\exp(z^{[L]}_i)}\]

<p>The actual values are represented as one-hot vectors, meaning that an actual value of class $j$ is represented by a vector in $\mathbb R^C$ where the $j$th component is 1 and the reset are 0. As always, when we vectorize things, each $a^{(i)[L]}$ are arranged as rows in the matrix $A^{[L]}$ so that the $i,j$th component of $A^{[L]}$ is</p>

\[A^{[L]}_{i,j}:=\frac{\exp({Z^{[L]}_{i,j})}}{\sum_{t=1}^C\exp (Z^{[L]}_{i,t})}\]

<p>and similarly for $Y$.</p>

<p>For the loss function, we use cross-entropy again modified to work with our setup here involving multiple classes:</p>

\[\sum_{j=1}^C-y^{(i)}_j\log_2\hat y^{(i)}_j\]

<p>which is equivalent to</p>

\[-\log_2\hat y^{(i)}_j\]

<p>where $j$ is the true class. Again, for our analytic calculations, we use the first form, which is differentiable. Ultimately, we want to minimize the mean cross-entropy loss</p>

\[f(W)=\frac 1m\sum_{i=1}^m\sum_{j=1}^C-y^{(i)}_j\log_2\hat y^{(i)}_j\]

<p>which in vectorized form is</p>

\[f(W)=-\frac 1m\sum(Y\odot(\log_2\circ A^{[L]}))\]

<p>where the sum takes place over all the entries in the matrix. Thereâ€™s a couple operations here that we havenâ€™t yet seen within our matrix calculus framework so letâ€™s briefly go over that now.</p>

<h3 id="matrix-calculus-elementwise-multiplication">Matrix calculus: elementwise multiplication</h3>

<p>Let</p>

\[\begin{align*}
G:X\mapsto X\odot C\\
G:\mathbb R^{m\times n}\to\mathbb R^{m\times n}
\end{align*}\]

<p>where $C\in\mathbb R^{m\times n}$â€‹ is a constant. If $f$ is a matrix-to-scalar function taking $G$ as input, then</p>

\[\begin{align*}
\frac{df}{dX_{i,j}}&amp;=\sum_{k,\ell}\frac{df}{dG_{k,\ell}}\cdot\frac{dG_{k,\ell}}{dX_{i,j}}\tag{multivariable chain rule}\\
&amp;=\sum_{k,\ell}\frac{df}{dG_{k,\ell}}\cdot\frac{d}{dX_{i,j}}(X_{k,\ell}\cdot C_{k,\ell})\\
&amp;=\sum_{k,\ell}\frac{df}{dG_{k,\ell}}\cdot 1_{k=i,\ell=j}\cdot C_{k,\ell}\\
&amp;=\frac{df}{dG_{i,j}}\cdot C_{i,j}\\
\implies\frac{df}{dX}&amp;=\frac{df}{dG}\odot C
\end{align*}\]

<h3 id="matrix-calculus-matrix-sum">Matrix calculus: matrix sum</h3>

<p>Let</p>

\[\begin{align*}
f:G\mapsto\sum G\\
f:\mathbb R^{m\times n}\to\mathbb R
\end{align*}\]

<p>Then</p>

\[\begin{align*}
\frac{df}{dG_{i,j}}&amp;=\frac{d}{dG_{i,j}}\sum_{k,\ell}G_{k,\ell}\\
&amp;=\frac{d}{dG_{i,j}}G_{i,j}\\
&amp;=1\\
\implies \frac{df}{dG}&amp;=1.
\end{align*}\]

<p>the matrix of all 1s.</p>

<h3 id="tying-things-together-1">Tying things together</h3>

<p>Using the above results, we have</p>

\[\begin{align*}
\frac{df}{dA^{[L]}}&amp;=-\frac 1m\cdot\frac{d\left(\sum(Y\odot (\log_2 \circ A^{[L]}))\right)}{dA^{[L]}}\\
&amp;=-\frac 1m\cdot\frac{d\left(\sum(Y\odot (\log_2 \circ A^{[L]}))\right)}{d(\log_2\circ A^{[L]})}\odot \frac{1}{\ln 2}\oslash A^{[L]}\\
&amp;=-\frac{1}{m\ln 2}\cdot \frac{d\left(\sum(Y\odot (\log_2 \circ A^{[L]}))\right)}{d(\log_2\circ A^{[L]})}\oslash A^{[L]}\\
&amp;=-\frac{1}{m\ln 2}\cdot Y\odot  \frac{d\left(\sum(Y\odot (\log_2 \circ A^{[L]}))\right)}{d(Y\odot (\log_2 \circ A^{[L]})))}\oslash A^{[L]}\\
&amp;=-\frac{1}{m\ln 2}\cdot Y\odot 1\oslash A^{[L]}\\
&amp;=-\frac{1}{m\ln 2}\cdot Y\oslash A^{[L]}
\end{align*}\]

<p>where $\oslash$ denotes elementwise division.</p>

<p>We also have</p>

\[\begin{align*}
\frac{df}{dZ^{[L]}_{i,j}}&amp;=\sum_{k,\ell}\frac{df}{dA^{[L]}_{k,\ell}}\cdot\frac{dA_{k,\ell}^{[L]}}{dZ_{i,j}^{[L]}}\\
&amp;=\sum_{k,\ell}-\frac{1}{m\ln 2}\cdot\frac{Y_{k,\ell}}{A^{[L]}_{k,\ell}}\cdot\frac{d}{dZ^{[L]}_{i,j}}\left(\frac{\exp({Z^{[L]}_{k,\ell})}}{\sum_{t=1}^C\exp (Z^{[L]}_{k,t})}\right)\\
&amp;=-\frac{1}{m\ln 2}\sum_{k,\ell}\frac{Y_{k,\ell}}{A^{[L]}_{k,\ell}}\cdot\frac{1}{\left(\sum_{t=1}^C\exp(Z_{k,t}^{[L]})\right)^2}\cdot\left(\sum_{t=1}^C\exp(Z_{k,t}^{[L]})\cdot1_{k=i,\ell=j}\exp Z_{k,\ell}^{[L]}-\exp Z_{k,\ell}^{[L]}\cdot 1_{k=i}\exp(Z_{k,j}^{[L]})\right)\\
&amp;=-\frac{1}{m\ln 2}\left(\frac{Y_{i,j}}{A_{i,j}^{[L]}}\cdot\frac{1}{\sum_{t=1}^C\exp(Z_{i,t}^{[L]})}\cdot \exp Z_{i,j}^{[L]}-\sum_\ell\frac{Y_{i,\ell}}{A_{i,\ell}^{[L]}}\cdot \frac{1}{\left(\sum_{t=1}^C\exp(Z_{i,t}^{[L]})\right)^2}\cdot \exp Z_{i,\ell}^{[L]}\exp(Z_{i,j}^{[L]})\right)\\
&amp;=-\frac{1}{m\ln 2}\cdot\frac{\exp Z_{i,j}^{[L]}}{\sum_{t=1}^C\exp(Z_{i,t}^{[L]})}\cdot\left(\frac{Y_{i,j}}{A_{i,j}^{[L]}}-\sum_\ell\frac{Y_{i,\ell}}{A_{i,\ell}^{[L]}}\cdot\frac{\exp Z_{i,\ell}^{[L]}}{\sum_{t=1}^C\exp(Z_{i,t}^{[L]})}\right)\\
&amp;=-\frac 1{m\ln 2}\cdot A_{i,j}^{[L]}\cdot\left(\frac{Y_{i,j}}{A_{i,j}^{[L]}}-\sum_\ell\frac{Y_{i,\ell}}{A_{i,\ell}^{[L]}}\cdot A_{i,\ell}^{[L]}\right)\\
&amp;=-\frac 1{m\ln 2}\cdot Y_{i,j}+\frac{1}{m\ln 2}\cdot A_{i,j}^{[L]}\cdot\sum_\ell Y_{i,\ell}\\
&amp;=\frac{1}{m\ln 2}\cdot (A_{i,j}^{[L]}-Y_{i,j})\\
\implies \frac{df}{dZ^{[L]}}&amp;=\frac 1{m\ln 2}\cdot (A^{[L]}-Y)
\end{align*}\]

<!--We want to be able to take derivatives of $f$ with respect to $A^{[L]}$ and $Z^{[L]}$ and there are two operations here which we have not yet seen in our matrix calculus framework: broadcasted elementwise division, and summing over all entries of a matrix.

### Matrix calculus: broadcasted elementwise division

First let's deal with broadcasted elementwise division.

Let
$$
G:X\mapsto C\oslash X
$$


where $X\in\mathbb R^{1\times n}$ is a row vector, $C\in\mathbb R^{m\times n}$ is a constant matrix, and the division is broadcasted. If $f$ is a matrix-to-scalar function taking $G$ as input, then


$$
\begin{align*}
\frac{df}{dX_{1,j}}&=\sum_{k,\ell}\frac{df}{dG_{k,\ell}}\cdot\frac{dG_{k,\ell}}{dX_{1,j}}\tag{multivariable chain rule}\\
&=\sum_{k,\ell}\frac{df}{dG_{k,\ell}}\cdot\frac{d}{dX_{1,j}}(C_{k,\ell}/X_{1,\ell})\\
&=\sum_{k,\ell}\frac{df}{dG_{k,\ell}}\cdot 1_{\ell=j}\cdot-\frac{C_{k,\ell}}{X_{1,\ell}^2}\\
&=\sum_{k}-\frac{df}{dG_{k,j}}\cdot\frac{C_{k,j}}{X_{1,j}^2}\\
&=-\frac{1}{X_{1,j}^2}\sum_k\frac{df}{dG_{k,j}}\cdot C_{k,j}\\
&=-\frac{1}{X_{1,j}^2}\sum_k(\frac{df}{dG})^T_{j,k}\cdot C_{k,j}\\
\implies \frac{df}{dX}&=-\text{diag}_\text{rows}((\frac{df}{dG})^T\cdot C)\oslash (X\odot X)
\end{align*}
$$


where $\text{diag}_{\text{rows}}(X)$ means taking the diagonal entries of the matrix $X$ and placing them as entries of a row vector.

In the context of vectorized softmax, we actually want the inputs to be a column vector i.e. $X\in\mathbb R^{m\times 1}$. In this case, following similar logic, we get (exercise to the reader)


$$
\frac{df}{dX}=-\text{diag}_\text{columns}(\frac{df}{dG}\cdot C^T)\oslash (X\odot X)
$$

### Matrix calculus: broadcasted elementwise multiplication

For the sake of completeness, let's also look at broadcasted elementwise multiplication. Let
$$
G:X\mapsto C\odot X
$$


where $X\in\mathbb R^{1\times n}$ is a row vector, $C\in\mathbb R^{m\times n}$ is a constant matrix, and the multiplication is broadcasted. If $f$ is a matrix-to-scalar function taking $G$ as input, then


$$
\begin{align*}
\frac{df}{dX_{1,j}}&=\sum_{k,\ell}\frac{df}{dG_{k,\ell}}\cdot\frac{dG_{k,\ell}}{dX_{1,j}}\tag{multivariable chain rule}\\
&=\sum_{k,\ell}\frac{df}{dG_{k,\ell}}\cdot\frac{d}{dX_{1,j}}(C_{k,\ell}\cdot X_{1,\ell})\\
&=\sum_{k,\ell}\frac{df}{dG_{k,\ell}}\cdot 1_{\ell=j}\cdot C_{k,\ell}\\
&=\sum_{k}\frac{df}{dG_{k,j}}\cdot C_{k,j}\\
&=\sum_k(\frac{df}{dG})^T_{j,k}\cdot C_{k,j}\\
\implies \frac{df}{dX}&=\text{diag}_{\text{rows}}((\frac{df}{dG})^T\cdot C)
\end{align*}
$$


If the inputs are a column vector i.e. $X\in\mathbb R^{m\times 1}$, then (exercise to the reader)


$$
\frac{df}{dX}=\text{diag}_{\text{columns}}(\frac{df}{dG}\cdot C^T)
$$

### Tying things together

Recall that


$$
A^=(\exp\circ Z^{[L]})\oslash\left(\sum_{\text{columns}}\exp\circ Z^{[L]}\right)
$$


Using our matrix calculus framework, we have


$$
\begin{align*}
\frac{df}{dA^{[L]}}&=
\end{align*}
$$
-->


      </div>
    </div>
    
    
    <div class="row">
      <div class="col col-12">
        
        <div id="disqus_thread" class="my-5"></div>
        <script>
          /**
          *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
          *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables    */
          var disqus_config = function () {
            this.page.url = "/machine-learning/neural-networks-2.html";  // Replace PAGE_URL with your page's canonical URL variable
            this.page.identifier = "Neural Networks 2"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
          };
          (function () { // DON'T EDIT BELOW THIS LINE
            var d = document, s = d.createElement('script');
            s.src = 'https://pilex-github.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
          })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by
            Disqus.</a></noscript>
        

      </div>
    </div>
  </div>

  <script>
    $("table").attr("class", "table");
  </script>

  <footer>
    <hr>
    <p class="centered"
      style="margin: 15px; margin-left: auto; margin-right: auto; font-size: 14px; text-align: center">
      Copyright Alex Tan &copy; 2022
    </p>
  </footer>
</body>

</html>